{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48fd24af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geyu/projects/my-test/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from tqdm.auto import tqdm\n",
    "import torchaudio\n",
    "from dataclasses import dataclass, field\n",
    "import evaluate\n",
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a39c9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geyu/projects/my-test/.venv/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = '../data'\n",
    "FINTUNED_MODEL = '../models/wav2vec2-large-960h-cv'\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "cv_model = Wav2Vec2ForCTC.from_pretrained(FINTUNED_MODEL).to(device)\n",
    "cv_processor = Wav2Vec2Processor.from_pretrained(FINTUNED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d909525",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_INDICES = pd.read_csv(f'{ROOT_DIR}/cv-valid-dev.csv')\n",
    "DEV_DATA_BASE = f\"{ROOT_DIR}/cv-valid-dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "223e3733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(file, eval_model, processor):\n",
    "    # try:\n",
    "    # Load audio file with soundfile\n",
    "    audio_array, sample_rate = sf.read(file)\n",
    "    \n",
    "    # Convert to mono if stereo\n",
    "    if len(audio_array.shape) > 1:\n",
    "        audio_array = audio_array.mean(axis=1)\n",
    "    \n",
    "    # Resample to 16kHz if needed\n",
    "    if sample_rate != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "        audio_array = torch.from_numpy(audio_array).float()\n",
    "        audio_array = resampler(audio_array).numpy()\n",
    "        sample_rate = 16000\n",
    "    \n",
    "    # Get duration\n",
    "    \n",
    "    # Normalize audio array\n",
    "    audio_array = audio_array / np.max(np.abs(audio_array))\n",
    "    \n",
    "        # Process audio with Wav2Vec2\n",
    "    input_values = processor(\n",
    "        audio_array, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=\"longest\",\n",
    "        sampling_rate=sample_rate\n",
    "    ).input_values.to(device)\n",
    "\n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        logits = eval_model(input_values).logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = processor.batch_decode(predicted_ids)[0]\n",
    "\n",
    "\n",
    "    return transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "917519da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_hot_words(transcription, hot_words):\n",
    "    \"\"\"\n",
    "    Detect hot words in the transcription.\n",
    "    \"\"\"\n",
    "    detected = []\n",
    "    for word in hot_words:\n",
    "        if re.search(r'\\b' + re.escape(word) + r'\\b', transcription, re.IGNORECASE):\n",
    "            detected.append(word)\n",
    "    return detected\n",
    "\n",
    "def output_hot_word_lst(df_with_transcription, hot_words, saving_path='./detected.txt'):\n",
    "    \"\"\"\n",
    "    Output the detected hot words to a file.\n",
    "    \"\"\"\n",
    "    file_name_lst = []\n",
    "    for i in tqdm(range(len(df_with_transcription))):\n",
    "        transcription = df_with_transcription.iloc[i]['transcription']\n",
    "        detected = detect_hot_words(transcription, hot_words)\n",
    "        if detected:\n",
    "            file_name_lst.append(df_with_transcription.iloc[i]['filename'])\n",
    "    with open(saving_path, 'w') as f:\n",
    "        for file_name in file_name_lst:\n",
    "            f.write(file_name + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23e8208e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 1371/4076 [00:34<01:11, 37.96it/s]/tmp/ipykernel_3251052/4231139856.py:20: RuntimeWarning: invalid value encountered in divide\n",
      "  audio_array = audio_array / np.max(np.abs(audio_array))\n",
      "100%|██████████| 4076/4076 [01:40<00:00, 40.38it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for i in tqdm(range(len(DEV_INDICES))):\n",
    "    row = DEV_INDICES.iloc[i]\n",
    "    file_path = f\"{DEV_DATA_BASE}/{row['filename']}\"\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File {file_path} does not exist.\")\n",
    "        continue\n",
    "    \n",
    "    transcription = transcribe(file_path, cv_model, cv_processor)\n",
    "    \n",
    "    predictions.append(transcription)\n",
    "\n",
    "DEV_INDICES['transcription'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1c14ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_INDICES.to_csv('./inference_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01b427ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOT_WORDS = [\"be careful\", \"destroy\",  \"stranger\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f3f1582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4076/4076 [00:00<00:00, 26456.43it/s]\n"
     ]
    }
   ],
   "source": [
    "output_hot_word_lst(DEV_INDICES, HOT_WORDS, saving_path='./detected.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92621fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
